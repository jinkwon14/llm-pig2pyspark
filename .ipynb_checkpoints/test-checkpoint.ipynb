{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Transcribe \n",
    "* Langchain\n",
    "* LangSmith\n",
    "* Semantic Kernel\n",
    "* Async Calls\n",
    "* Build APIs\n",
    "* Integrate Airflow, DB, Logging\n",
    "\n",
    "Models:\n",
    "* Mistral Dolphin: \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install and Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load PIG Code (optionsal: Upload sample data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://deepgram.com/learn/local-llm-chatbot-that-can-run-code-searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.1. LLM transcriber PIG2PySpark\n",
    "# Prompt: \n",
    "# You are an experienced Software Engineer and Machine Learning Engineer fluent in PIG and PySpark coding languages. \n",
    "# Rewrite the following PIG code into PySpark so that they can perform identical tasks and output identical results given same input data. \n",
    "# PIG Code: {pig_code}\n",
    "# A.2. Code Parser: Parse and save PySpark code \n",
    "\n",
    "# B. Sample Data Builder \n",
    "# C. PIG Interpreter \n",
    "# D. PySpark Interpreter \n",
    "\n",
    "# If sample data NOT available (run B.)\n",
    "  # Run PIG code and generate output \n",
    "  # 1. Generate PySpark code from PIG (run A.1) and parse/save the PySpark Code (run A.2)\n",
    "# 2. Run against sample data in a separate module.\n",
    "# 3. Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /workspace\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory:\", current_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred during Pig script execution:\n",
      "2024-05-02 23:05:26,996 [main] INFO  org.apache.pig.Main - Apache Pig version 0.17.0 (r1797386) compiled Jun 02 2017, 15:41:58\n",
      "2024-05-02 23:05:26,996 [main] INFO  org.apache.pig.Main - Logging error messages to: /workspace/pig_1714691126990.log\n",
      "2024-05-02 23:05:27,015 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - user.name is deprecated. Instead, use mapreduce.job.user.name\n",
      "2024-05-02 23:05:27,261 [main] INFO  org.apache.pig.impl.util.Utils - Default bootup file /root/.pigbootup not found\n",
      "2024-05-02 23:05:27,322 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2024-05-02 23:05:27,323 [main] INFO  org.apache.pig.backend.hadoop.executionengine.HExecutionEngine - Connecting to hadoop file system at: file:///\n",
      "2024-05-02 23:05:27,341 [main] INFO  org.apache.pig.PigServer - Pig Script ID for the session: PIG-pig1.pig-49022241-9885-4fc4-ba9e-281674bb9e72\n",
      "2024-05-02 23:05:27,341 [main] WARN  org.apache.pig.PigServer - ATS is disabled since yarn.timeline-service.enabled set to false\n",
      "2024-05-02 23:05:27,615 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2024-05-02 23:05:27,619 [main] ERROR org.apache.pig.tools.grunt.Grunt - ERROR 6000: <file ./scripts/pig1.pig, line 21, column 0> Output Location Validation Failed for: 'file:///workspace/output/high_value_transactions More info to follow:\n",
      "Output directory file:/workspace/output/high_value_transactions already exists\n",
      "Details at logfile: /workspace/pig_1714691126990.log\n",
      "2024-05-02 23:05:27,636 [main] INFO  org.apache.pig.Main - Pig script completed in 1 second and 18 milliseconds (1018 ms)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def run_pig_script(script_path, data_path):\n",
    "    # Set up the environment variable to point to the directory containing the data file\n",
    "    os.environ['PIG_DATA_PATH'] = data_path\n",
    "\n",
    "    # Execute the Pig script using subprocess, assuming Pig is installed and configured to run in local mode\n",
    "    result = subprocess.run(['pig', '-x', 'local', '-f', script_path], capture_output=True, text=True)\n",
    "    \n",
    "    # Check the results of the Pig script execution\n",
    "    if result.returncode != 0:\n",
    "        print(\"Error occurred during Pig script execution:\")\n",
    "        print(result.stderr)\n",
    "    else:\n",
    "        print(\"Pig script executed successfully. Output:\")\n",
    "        print(result.stdout)\n",
    "\n",
    "# Define the path to the Pig script and the directory containing the data file\n",
    "pig_script = './scripts/pig1.pig'\n",
    "csv_data = './data/'\n",
    "\n",
    "# Execute the Pig script\n",
    "run_pig_script(pig_script, csv_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depStore</th>\n",
       "      <th>total_sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>store1</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store2</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store3</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store3</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          depStore  total_sales\n",
       "store1  2022-01-02          300\n",
       "store2  2022-01-02          250\n",
       "store3  2022-01-01          400\n",
       "store3  2022-01-02          500"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the output file created by Pig\n",
    "output_file = 'output/high_value_transactions/part-m-00000'  # Adjust path as needed\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(output_file, names=['depStore', 'total_sales'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LLM Layer - Pig2PySpark \n",
    "* https://medium.com/@yash9439/unleashing-the-power-of-falcon-code-a-comparative-analysis-of-implementation-approaches-803048ce65dc\n",
    "* ref: https://medium.com/@ajay_khanna/leveraging-llama2-0-for-question-answering-on-your-own-data-using-cpu-aa6f75868d2d\n",
    "* ref: https://medium.com/@murtuza753/using-llama-2-0-faiss-and-langchain-for-question-answering-on-your-own-data-682241488476\n",
    "* https://wellsr.com/python/fine-tuning-llama2-for-question-answering-tasks/\n",
    "* https://www.kaggle.com/code/gpreda/rag-using-llama-2-langchain-and-chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"-- Load the data from a CSV file\\ntransactions = LOAD 'data/sample1.csv' USING PigStorage(',') \\n    AS (depStore:chararray, date:chararray, amount:int);\\n\\n-- Filter transactions to include only those where the amount is greater than 200\\nhigh_value_transactions = FILTER transactions BY amount > 200;\\n\\n-- Group the transactions by store\\ngrouped_by_store = GROUP high_value_transactions BY depStore;\\n\\n-- Calculate total and average sales per depStore\\nsales_summary = FOREACH grouped_by_store GENERATE \\n    group AS depStore,\\n    SUM(high_value_transactions.amount) AS total_sales,\\n    AVG(high_value_transactions.amount) AS average_sales;\\n\\n-- Store the summary in a CSV file\\nSTORE sales_summary INTO 'output/sales_summary' USING PigStorage(',');\\n\\n-- Optional: Just for demonstration, store filtered data to another directory\\nSTORE high_value_transactions INTO 'output/high_value_transactions' USING PigStorage(',');\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading shards:   0%|          | 0/59 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "# model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "model_id = \"mistralai/Mixtral-8x22B-Instruct-v0.1\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"You are a highly experienced software engineer and machine learning engineer fluent in both PIG and PySpark.\"},\n",
    "#     {\"role\": \"user\", \"content\": f\"Re-write the following PIG code into PySpark code. Make sure to only share PySpark so that the two codes are logically identical and output identical results given input. PIG code: {pig_script_code}\"},\n",
    "# ]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": f\"You are a highly experienced software engineer and machine learning engineer fluent in both PIG and PySpark. Re-write the following PIG code into PySpark code. Make sure to only share PySpark so that the two codes are logically identical and output identical results given input. PIG code: {pig_script_code}\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain as lc\n",
    "\n",
    "# Define the model ID and initialize the LLM\n",
    "model_id = \"mistralai/Mixtral-8x22B-Instruct-v0.1\"\n",
    "llm = lc.LLM.from_pretrained(\n",
    "    model_id=model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"bfloat16\"\n",
    ")\n",
    "\n",
    "# Initial prompt setup\n",
    "initial_prompt = \"You are a highly experienced software engineer and machine learning engineer fluent in both PIG and PySpark. Re-write the following PIG code into PySpark code. Make sure to only share PySpark so that the two codes are logically identical and output identical results given input. PIG code: {pig_script_code}\"\n",
    "\n",
    "# Define a function to execute PySpark code and capture any errors\n",
    "def execute_pyspark_code(code):\n",
    "    try:\n",
    "        # Assuming a function `execute_code` that runs PySpark code and returns results or errors\n",
    "        result = execute_code(code)\n",
    "        return result, None\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "# Define a function to refine code using error messages\n",
    "def refine_code_with_error(code, error_message):\n",
    "    feedback_prompt = f\"{initial_prompt} However, the following error occurred when executing your previous PySpark code: {error_message} Please fix it. Previous PySpark code: {code}\"\n",
    "    messages = [{\"role\": \"user\", \"content\": feedback_prompt}]\n",
    "    result = llm_chain.run(input=messages)\n",
    "    return result.generated_text\n",
    "\n",
    "# Create a chain for generating PySpark code\n",
    "llm_chain = lc.Chain(\n",
    "    steps=[\n",
    "        lc.steps.TextGeneration(\n",
    "            llm=llm,\n",
    "            max_new_tokens=256,\n",
    "            temperature=0.6,\n",
    "            top_p=0.9,\n",
    "            end_tokens=[\"\", llm.tokenizer.eos_token]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initial code generation\n",
    "initial_messages = [{\"role\": \"user\", \"content\": initial_prompt}]\n",
    "initial_result = llm_chain.run(input=initial_messages)\n",
    "generated_code = initial_result.generated_text\n",
    "\n",
    "# Attempt to execute the generated code\n",
    "execution_result, error = execute_pyspark_code(generated_code)\n",
    "\n",
    "# If an error occurs, refine the code\n",
    "if error:\n",
    "    refined_code = refine_code_with_error(generated_code, error)\n",
    "    print(\"Refined PySpark Code:\", refined_code)\n",
    "else:\n",
    "    print(\"Successfully executed PySpark Code:\", execution_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers\n",
    "# import torch\n",
    "\n",
    "# # model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_id = \"gradientai/Llama-3-8B-Instruct-Gradient-1048k\"\n",
    "\n",
    "# pipeline = transformers.pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model_id,\n",
    "#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "\n",
    "# # messages = [\n",
    "# #     {\"role\": \"system\", \"content\": \"You are a highly experienced software engineer and machine learning engineer fluent in both PIG and PySpark.\"},\n",
    "# #     {\"role\": \"user\", \"content\": f\"Re-write the following PIG code into PySpark code. Make sure to only share PySpark so that the two codes are logically identical and output identical results given input. PIG code: {pig_script_code}\"},\n",
    "# # ]\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": f\"You are a highly experienced software engineer and machine learning engineer fluent in both PIG and PySpark. Re-write the following PIG code into PySpark code. Make sure to only share PySpark so that the two codes are logically identical and output identical results given input. PIG code: {pig_script_code}\"},\n",
    "# ]\n",
    "\n",
    "# prompt = pipeline.tokenizer.apply_chat_template(\n",
    "#         messages, \n",
    "#         tokenize=False, \n",
    "#         add_generation_prompt=True\n",
    "# )\n",
    "\n",
    "# terminators = [\n",
    "#     pipeline.tokenizer.eos_token_id,\n",
    "#     pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "# ]\n",
    "\n",
    "# outputs = pipeline(\n",
    "#     prompt,\n",
    "#     max_new_tokens=256,\n",
    "#     eos_token_id=terminators,\n",
    "#     do_sample=True,\n",
    "#     temperature=0.6,\n",
    "#     top_p=0.9,\n",
    "# )\n",
    "# print(outputs[0][\"generated_text\"][len(prompt):])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers\n",
    "# import torch\n",
    "\n",
    "# # model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "# model_id = \"mistralai/Mixtral-8x22B-Instruct-v0.1\"\n",
    "\n",
    "# pipeline = transformers.pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model_id,\n",
    "#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#     device_map=\"auto\",\n",
    "# )\n",
    "\n",
    "\n",
    "# # messages = [\n",
    "# #     {\"role\": \"system\", \"content\": \"You are a highly experienced software engineer and machine learning engineer fluent in both PIG and PySpark.\"},\n",
    "# #     {\"role\": \"user\", \"content\": f\"Re-write the following PIG code into PySpark code. Make sure to only share PySpark so that the two codes are logically identical and output identical results given input. PIG code: {pig_script_code}\"},\n",
    "# # ]\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": f\"You are a highly experienced software engineer and machine learning engineer fluent in both PIG and PySpark. Re-write the following PIG code into PySpark code. Make sure to only share PySpark so that the two codes are logically identical and output identical results given input. PIG code: {pig_script_code}\"},\n",
    "# ]\n",
    "\n",
    "# prompt = pipeline.tokenizer.apply_chat_template(\n",
    "#         messages, \n",
    "#         tokenize=False, \n",
    "#         add_generation_prompt=True\n",
    "# )\n",
    "\n",
    "# terminators = [\n",
    "#     pipeline.tokenizer.eos_token_id,\n",
    "#     pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "# ]\n",
    "\n",
    "# outputs = pipeline(\n",
    "#     prompt,\n",
    "#     max_new_tokens=256,\n",
    "#     eos_token_id=terminators,\n",
    "#     do_sample=True,\n",
    "#     temperature=0.6,\n",
    "#     top_p=0.9,\n",
    "# )\n",
    "# print(outputs[0][\"generated_text\"][len(prompt):])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sure! Below is a Python code template that uses an LLM to convert PIG code to PySpark code, then automatically tests and refines the PySpark code based on feedback. This example assumes that you are using an API to interact with an LLM and are capable of running PySpark scripts programmatically. Here, I’ll outline a simplified version that focuses on the core loop and error handling.\n",
    "\n",
    "# ### Python Code Example\n",
    "\n",
    "# ```python\n",
    "# import requests\n",
    "\n",
    "# def get_pyspark_code(pig_code):\n",
    "#     \"\"\" Send PIG code to LLM and receive initial PySpark translation \"\"\"\n",
    "#     response = requests.post('https://api.example.com/translate', json={'code': pig_code})\n",
    "#     return response.json()['pyspark_code']\n",
    "\n",
    "# def test_pyspark_code(pyspark_code, test_input):s\n",
    "#     \"\"\"\n",
    "#     Run PySpark code and return the output.\n",
    "#     This function would realistically run the code in a separate environment and capture outputs.\n",
    "#     \"\"\"\n",
    "#     # Placeholder for actual code execution and output capturing\n",
    "#     # You would replace this with actual execution logic\n",
    "#     output = run_pyspark_script(pyspark_code, test_input)\n",
    "#     return output\n",
    "\n",
    "# def run_pyspark_script(pyspark_code, input_data):\n",
    "#     \"\"\" A mock function to execute PySpark code - replace with actual execution logic \"\"\"\n",
    "#     # This would involve setting up Spark session and running the code\n",
    "#     # For simplicity, this is just a placeholder\n",
    "#     return \"Mock output based on \" + input_data\n",
    "\n",
    "# def main(pig_code, test_input, expected_output):\n",
    "#     pyspark_code = get_pyspark_code(pig_code)\n",
    "#     attempts = 0\n",
    "#     max_attempts = 10  # Prevent infinite loops by limiting the number of attempts\n",
    "\n",
    "#     while attempts < max_attempts:\n",
    "#         attempts += 1\n",
    "#         output = test_pyspark_code(pyspark_code, test_input)\n",
    "#         if output == expected_output:\n",
    "#             print(\"Success! PySpark code matches the expected output.\")\n",
    "#             break\n",
    "#         else:\n",
    "#             print(\"Mismatch or error detected. Refining code...\")\n",
    "#             # Send feedback and get refined code\n",
    "#             response = requests.post('https://api.example.com/refine', json={\n",
    "#                 'original_code': pyspark_code,\n",
    "#                 'output': output,\n",
    "#                 'expected_output': expected_output\n",
    "#             })\n",
    "#             pyspark_code = response.json()['refined_pyspark_code']\n",
    "#     else:\n",
    "#         print(\"Maximum attempts reached. Final PySpark code may need manual review.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     pig_code = \"LOAD 'data' AS (a:int, b:int, c:int); FILTER a by a > 0; STORE a INTO 'output';\"\n",
    "#     test_input = \"Sample input data that your PIG code expects\"\n",
    "#     expected_output = \"Expected output format or data\"\n",
    "#     main(pig_code, test_input, expected_output)\n",
    "# ```\n",
    "\n",
    "# ### Key Components:\n",
    "\n",
    "# 1. **API Interaction**: This script assumes the existence of two endpoints: one to translate PIG to PySpark, and another to refine the PySpark code based on feedback.\n",
    "# 2. **Execution and Testing**: It simplistically represents the PySpark execution. In a real-world scenario, this would involve using a `subprocess` to run a Spark job, capturing its output, and perhaps even interacting with a test database or data storage.\n",
    "# 3. **Loop and Feedback**: The script uses a loop to refine the PySpark code based on mismatches between expected and actual outputs, up to a maximum number of iterations to prevent infinite loops.\n",
    "\n",
    "# ### Enhancements for Production:\n",
    "\n",
    "# - **Error Handling**: Implement robust error handling around API calls and PySpark execution.\n",
    "# - **Logging**: Add detailed logging for each step to facilitate debugging and monitoring.\n",
    "# - **Security**: Secure API interactions and handle data securely, especially when working with sensitive or large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================================================================================\n",
    "# parse Python code inside the code cell (TODO: How to ensure code is consistently inside the triple back ticks?) \n",
    "# How to loop the code so that it runs until correct code is written? \n",
    "# How does Langchain come into play? \n",
    "# When debugging: 1) provide loaded data head 2) code 3) error message or output if run was successful --> output updated code\n",
    "# ==============================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, pipeline, AutoModelForCausalLM\n",
    "# import torch\n",
    "\n",
    "# # Define the model\n",
    "# # model_name = \"tiiuae/falcon-7b-instruct\"\n",
    "\n",
    "# # Save model and tokenizer to a specific directory (optional)\n",
    "# # model.save_pretrained('./model_cache/falcon-7b-instruct')\n",
    "# # tokenizer.save_pretrained('./model_cache/falcon-7b-instruct')\n",
    "\n",
    "# model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "# # Download and cache model and tokenizer\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "# model.save_pretrained('./model_cache/Meta-Llama-3-8B-Instruct')\n",
    "# del model \n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# tokenizer.save_pretrained('./model_cache/Meta-Llama-3-8B-Instruct')\n",
    "# del tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the model and tokenizer from the cache for use\n",
    "# tokenizer = AutoTokenizer.from_pretrained('./model_cache/Meta-Llama-3-8B-Instruct')\n",
    "# model = AutoModelForCausalLM.from_pretrained('./model_cache/Meta-Llama-3-8B-Instruct')\n",
    "\n",
    "# # Setup the pipeline with local model and tokenizer\n",
    "# text_generation = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     device=0  # Assuming using the first GPU\n",
    "# )\n",
    "\n",
    "# # Generate text\n",
    "# generated_text = text_generation(\"Sample prompt text goes here\", max_length=50)\n",
    "# print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = f\"Re-write the following PIG code into PySpark code. Following is the PIG code: \\n {pig_script_code}\"\n",
    "# template = f\"\"\"\n",
    "# You are an intelligent software engineer and machine learning engineer. Re-write the following PIG code into PySpark code. Make sure to only share PySpark code so it's easy to copy and paste. \n",
    "# PIG code: {question}\n",
    "# --------------------------------------------------------------------\n",
    "# PySpark code:\"\"\"\n",
    "\n",
    "# sequences = pipeline(\n",
    "#     template,\n",
    "#     max_length=5000,\n",
    "#     do_sample=True,\n",
    "#     top_k=10,\n",
    "#     num_return_sequences=1,\n",
    "#     eos_token_id=tokenizer.eos_token_id,\n",
    "# )\n",
    "\n",
    "# for seq in sequences:\n",
    "#     print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Test PySpark Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt_starter(): \n",
    "    \"\"\"\n",
    "    Generate prompt to start transcribing PIG to PySpark.\n",
    "    \"\"\"\n",
    "\n",
    "def build_prompt_fix_error(): \n",
    "    \"\"\"\n",
    "    Generate prompt to fix error in PySpark code.\n",
    "    \"\"\"\n",
    "\n",
    "def build_prompt_fix_output(): \n",
    "    \"\"\"\n",
    "    Generate prompt to fix code output mismatch (between result from PIG and PySpark). \n",
    "    \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sum, avg\n",
    "\n",
    "\n",
    "def run_pyspark_code(code_dir, code_name, sample_data_dir): \n",
    "    # start PySpark server\n",
    "    # run code against test data\n",
    "\n",
    "    if error: \n",
    "        return error_message\n",
    "    else: \n",
    "        return result_df\n",
    "\n",
    "def check_resutls(pig_result_df, pyspark_result_df): \n",
    "    # return True if the results are identical \n",
    "    return is_same \n",
    "\n",
    "\n",
    "# loop until both pyspark code runs fine and output data from PIG and PYSpark are the same\n",
    "while not is_pyspark_pass or not is_result_identical:  \n",
    "    \n",
    "\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"Sales Summary\").getOrCreate()\n",
    "\n",
    "# Load the data from a CSV file\n",
    "transactions = spark.read.csv('data/sample1.csv', header=False, inferSchema=True)\n",
    "\n",
    "# Define your list of column names\n",
    "column_names = [\"store\", \"date\", \"amount\"]\n",
    "\n",
    "# Filter transactions to include only those where the amount is greater than 200\n",
    "high_value_transactions = transactions.filter(transactions.amount > 200)\n",
    "\n",
    "# Group the transactions by store\n",
    "grouped_by_store = high_value_transactions.groupBy(\"depStore\")\n",
    "\n",
    "# Calculate total and average sales per depStore\n",
    "sales_summary = grouped_by_store.agg({\"amount\": \"sum\"}).alias(\"total_sales\"), avg(\"amount\").alias(\"average_sales\")\n",
    "\n",
    "# Store the summary in a CSV file\n",
    "sales_summary.write.csv('output/sales_summary', header=True, sep=',')\n",
    "\n",
    "# Optional: Just for demonstration, store filtered data to another directory\n",
    "high_value_transactions.write.csv('output/high_value_transactions', header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from tabulate import tabulate\n",
    "\n",
    "def build_prompt_starter(pig_code):\n",
    "    \"\"\"\n",
    "    Generate prompt to start transcribing PIG to PySpark.\n",
    "    Returns a string with the starter prompt.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "    I need to convert the following Apache PIG script into Apache PySpark code. \n",
    "    The PySpark code should perform the same tasks and produce identical outputs as the PIG code. \n",
    "    Please ensure that the PySpark code uses DataFrame operations wherever possible and include comments explaining any complex parts or transformations.\n",
    "    \n",
    "    PIG Code: \n",
    "    {pig_code}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def build_prompt_fix_error(error_message):\n",
    "    \"\"\"\n",
    "    Generate prompt to fix error in PySpark code.\n",
    "    Returns a string with the prompt to fix errors.\n",
    "    \"\"\"\n",
    "    return f\"\"\"There was an error in your PySpark code: {error_message}. Please fix it and share an updated PySpark code.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "pig_output = tabulate(pig_output, headers='keys', tablefmt='psql', showindex=\"never\")\n",
    "pyspark_output = tabulate(pyspark_output, headers='keys', tablefmt='psql', showindex=\"never\")\n",
    "\n",
    "\n",
    "def build_prompt_fix_output(pig_output, pyspark_output):\n",
    "    \"\"\"\n",
    "    Generate prompt to fix code output mismatch between results from PIG and PySpark.\n",
    "    Returns a string with the prompt for fixing output mismatches.\n",
    "    \"\"\"\n",
    "    return f\"\"\"\n",
    "    The outputs between PIG and PySpark do not match. Please adjust the PySpark code so that the output from PySpark code is identical to that from PIG code. \n",
    "    Below are the two outputs with mismatch:\n",
    "\n",
    "    Pig Output (ground truth): \n",
    "    {pig_output}\n",
    "\n",
    "    \n",
    "    PySpark Output: \n",
    "    {pyspark_output}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def run_pyspark_code(code):\n",
    "    \"\"\"\n",
    "    Executes PySpark code, returns either error message or result DataFrame.\n",
    "    Assumes PySpark session and context are already set.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        exec(code)\n",
    "        return None, globals().get('sales_summary')  # Assuming 'sales_summary' is the result DataFrame\n",
    "    except Exception as e:\n",
    "        return str(e), None\n",
    "\n",
    "\n",
    "def check_results(pig_result_df, pyspark_result_df):\n",
    "    \"\"\"\n",
    "    Compare PIG and PySpark DataFrames to check if the results are identical.\n",
    "    \"\"\"\n",
    "    return pig_result_df.subtract(pyspark_result_df).count() == 0 and pyspark_result_df.subtract(pig_result_df).count() == 0\n",
    "\n",
    "\n",
    "# Set up PySpark\n",
    "spark = SparkSession.builder.appName(\"Sales Summary\").getOrCreate()\n",
    "\n",
    "# Initial PySpark code generation using an LLM (not shown here)\n",
    "pyspark_code = \"\"\"\n",
    "# Assume pyspark_code is filled with the initially generated code\n",
    "\"\"\"\n",
    "pig_result_df = spark.createDataFrame(...)  # Assume this is setup elsewhere\n",
    "\n",
    "# Run and refine PySpark code\n",
    "error_message, pyspark_result_df = run_pyspark_code(pyspark_code)\n",
    "while error_message or not check_results(pig_result_df, pyspark_result_df):\n",
    "    if error_message:\n",
    "        prompt = build_prompt_fix_error(error_message)\n",
    "    else:\n",
    "        prompt = build_prompt_fix_output()\n",
    "    # Here you would update `pyspark_code` based on the LLM's output (not shown here)\n",
    "    error_message, pyspark_result_df = run_pyspark_code(pyspark_code)\n",
    "\n",
    "# Results are now fine\n",
    "print(\"PySpark code executed successfully and results match PIG.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subprocess to test out sample codes: \n",
    "# link: https://www.google.com/search?q=Python+application+which+run+PIG+code&rlz=1C1OPNX_enUS1108US1108&oq=Python+application+which+run+PIG+code+&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigATIHCAMQIRigAdIBCTEwNTIzajBqN6gCALACAA&sourceid=chrome&ie=UTF-8\n",
    "\n",
    "# langchain \n",
    "\n",
    "# langsmith \n",
    "\n",
    "# streamlit \n",
    "\n",
    "# airflow \n",
    "\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
